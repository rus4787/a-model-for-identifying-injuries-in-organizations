# a-model-for-identifying-injuries-in-organizations

## Обучение моделей со следующими результатами:
- 4 модели с SimpleRNN: все модели не смогли выявить закономерность определения 1 класса, распределение было сопоставимо вероятностному (50%)
- 4 модели с GRU: все модели не смогли выявить закономерность определения 1 класса, распределение было сопоставимо вероятностному (50%)
- 8 низкоуровневых (простых) моделей с LSTM: все модели не смогли выявить закономерность определения 1 класса, распределение было сопоставимо вероятностному (50%)
- 2 сложных модели с LSTM: (Embedding(50) + BLSTM(8)x2 + Dropout(0.4, 0.3); Embedding(10) + LSTM(4) + Dense(100) + Flatten). Обе показали 95% результат по 1 классу (TP = 0.95, FP = 0.05)
- 4 модели с Conv1D: все модели справились с заданием. Но версии №1 (93%) и №3 (95%) имеют плохое распределение ошибки: обучение модели шло неровно, график ошибок имеет значительные всплески. Поэтому модель может выдать крайне нежелательный результат в каком то вероятностном случае. Версии №2 и №4 имеют по 98% верного предсказания нужного класса (TP = 0.98, FP = 0.02)
- 6 моделей с LSTM и Conv1D: все модели справились с заданием. Но они очень сложны и требуют крайне точной настройки (видно по графику ошибок как он "пляшет) - в нашем случае это лишняя трата ресурсов, а при возможном изменении параметров вводимых данных еще и сгоревший стул програмиста. В текущем состоянии их работу нельзя считать стабильной -, а так как у нас задача не "Войну и мир" по ролям раскидать, а проработать с контекстом на 1000 слов максимум то это того не стоит.... Поэтому их в расчет не беру
- модель LogisticRegression (З.Ы.я ее везде называют "логостической классификацией" по тексту, просто у нас задача классов и мне так кажется удобнее для твоего восприятия. А так это обычная логическая регрессия). Дополнительно использовали CountVectorizer (обработчик текста в вектор) и classification_report (деление на классы). Показала хороший результат: общий по 1 классу: f1-score = 96% (неверно определила 10 значений из 2414), а на проверочных данных 93% (неверно определила 3 значения из 80).

## Сравнению 5 моделей (ну и алгоритм):
- model_Conv_2: accuracy = 0.97
- model_Conv_4: accuracy = 0.97
- LogisticRegression (CountVectorizer + classification_report): accuracy = 0.96
- model_LSTM_7 (Embedding(50) + BLSTM(8)x2 + Dropout(0.4, 0.3): accuracy = 0.95
- model_LSTM_9 (Embedding(10) + LSTM(4) + Dense(100) + Flatten): accuracy = 0.95


## Результаты оценки
1. Две модели отбракованы по результатм оценки графика loss, в частности: model_LSTM_9 и model_Conv_4.
2. оставшиеся три модели LogisticRegression, model_Conv_2 и model_LSTM_7 оценены на метрики работы на проверочных данных. в результате получены следующие данные:
- Conv1D: Точность=1.0; Полнота=0.92; F1-score=0.96; Общая точность модели=0.98
- LogisticRegression: Точность=1.0; Полнота=0.88; F1-score=0.93; Общая точность модели=0.96
- LSTM: Точность=1.0; Полнота=0.83; F1-score=0.91; Общая точность модели=0.95
Таким образом, лучшие данные показала нейросеть Conv1D, немного хуже Logistic Regression.
3. Была проверенна скорость работы модели на 174894 строк. Время составило:
- LogisticRegression: 12 секунд
- Conv1D: 219 секунд
- LSTM: 1737.62 секунд
4. Было оценено предсказание моделями нужного классса на 174894 строках, из которых 577 содержат записи о несчастных случая Получены результаты: TP - верно определила "1" класс TN - верно определила "0" класс FP - неверно определила "1" класс FN - неверно определила "0" класс
- LogisticRegression: TP: 568, TN: 174289, FP: 28, FN: 9
- Conv1D: TP: 570, TN: 174265, FP: 52, FN: 7
- LSTM: TP: 557, TN: 172845, FP: 1472, FN: 20

По метрикам:
- LogisticRegression: Точность=0.95; Полнота=0.98; F1-score=0.97; Общая точность модели=1.0
- Conv1D: Точность=0.92; Полнота=0.99; F1-score=0.95; Общая точность модели=1.0
- LSTM: Точность=0.27; Полнота=0.97; F1-score=0.43; Общая точность модели=0.99

Напомню:
- Precision (точность) - насколько точно модель предсказывает несчастные случаи.
- Recall (полнота) - как модель обнаруживать все несчастные случаи.
- F1-score - это гармоническое среднее между точностью и полнотой.
- Accuracy (точность) - общая точность модели.

Нам важно обнаружитьне все случаи а их точность (по русски - можно предсказать 2000 вариантов как LSTM и "выбить" 97% первого класс. правда еще 1500 нулевого как первый определить. Это нам не надо. Нам лучше не определить какую-то проверку как несчастный случай, чем приписать нивиновному лишнего). Поэтому нам важен Precision.

5. ИТОГ: В результате оценки нами подобранно две модели:
- LogisticRegression с Precision = 0.95
- Conv1D с Precision = 0.92
- 
ИМХО:
- Если нужна модель для внутреннего пользования- то LogisticRegression: быстро, просто, интерпритируемо
- Если нужна модель для "понта" (продажи) - то Conv1D: целая нейросеть.
- Но есть еще один фактор: при небольших изменениях данных (ну начнут по другому писать) - сверточная сеть подстроится - она работает на контексте. Регрессия же начнет снижать точность. Но с другой стороны ее переучить минута времени. А если начнет лагать Conv1D, то скорее всего придется писать ее заново.

## FIPK_algoritm_accident - алгорим оценки текстовых полей таблиц по выявлению несчастных случаем на производстве.
1. Основная цель - автоматическая разметка данных на основании экспертного мнения. С задачей разметки данных на 100000 записей справялется оптимально.Может использоватся самостоятельно как более интерпретируемая замена ML. Может быть оценен по метрике precision. Легко изменяется. структурно состоит из двух связаных классов встроенных функций обработки. Отсутствует блок автоматизации подгрузки данных - неизвестна рабочая среда алгоритма. Вывод данных определен как дозапись данных в накопительную часть. Контроль записи - сверка имени записываемого файла.
2. Описание структуры:
- ввод данных через список двух zip файлов в переменной
- Первый класс XML2DataFrame - павсер по .csv. Вывод первого класса - список из двух таблиц в переменной datasets. Нужный датасет выделяется как datasets[0],datasets[1]
- Второй класс DataProcessor - алгоритм обработки. Принимает список датасетов из класса XML2DataFrame. На выход передает:
  - список обработанных датасетов типовой структуры с добавлеными столбцами: 'ACCIDENT' - факт несчастного случая (бинарный, type); 'DEADLY_OUTCOME' - факт смерти потерпервшего (бинарный, type)
  - селектированный датасет df_ML_erp в структуре ['ERPID', 'START_DATE', 'ORG_NAME', 'INN', 'ADDRESS', 'STATUS', 'INSP_TARGET', 'REASON_TEXT', 'ACCIDENT', 'DEADLY_OUTCOME']
  - селектированный датасет df_ML_erknm в структуре ['ERPID', 'START_DATE', 'INN', 'ADDRESS', 'STATUS', 'DATA_CONTENT', 'ORGANIZATION_DOCUMENT', 'ACCIDENT', 'DEADLY_OUTCOME'] Датасеты нужны для работы ML в последующем. Тогда в классе будет просто селекция таблиц, передача их на вход модели, получение двух таргетов ACCIDENT', 'DEADLY_OUTCOME' и добавление их к списку датасетов. Но ближайшиее время рекомендовано использование и алгоритма и сверточной сети параллельно в рамках A/B тестирования.
- Третий класс DatasetManager - обработчик выгрузки. На вход принимает список датасетов из DataProcessor. В классе происходит их деление по типам - ЕРКНМ и ЕРП (как в исходных данных проверок). Относительный или абсолютный путь указывается в self.erp_filename = 'erp.csv' и self.erknm_filename = 'erknm.csv' вместо 'erp.csv' и 'erknm.csv' соотвественно. На выход ничего не отдает.
- Четвертая функция def process_and_save_datasets - обработчик датасетов для ML. Используется временно в период тестирования сети. Принимает на вход два датасета df_ML_erp и df_ML_erknm. Осуществляет перевод столбцов "ERPID" и "INN" в тип int64, столбца "START_DATE" в тип дата. Сохраняются в два отдельных CSV файла с добавлением временной метки к их именам. Относительный или абсолютный путь указывается в вызове функции process_and_save_datasets(save_path="my_folder"). На выход ничего не отдает.

  
